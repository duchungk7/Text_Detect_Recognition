{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "#'''\n",
    "# Created on 18-10-15\n",
    "#\n",
    "# @Author: Greg Gao(laygin)\n",
    "#'''\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import imutils\n",
    "from pixellink_model import create_pixellink_model\n",
    "from pixellink_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\duchu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "r_mean = 123.\n",
    "g_mean = 117.\n",
    "b_mean = 104.\n",
    "rgb_mean = [r_mean, g_mean, b_mean]\n",
    "\n",
    "\n",
    "img_path = './samples/TOP_29_121222.jpg'\n",
    "save_weights = './weights/pixellink.h5'\n",
    "model = create_pixellink_model(acf='relu')\n",
    "model.load_weights(save_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = cv2.imread(img_path)\n",
    "image, *r = resize_image(image)\n",
    "image_ori = image.copy()\n",
    "image = image[...,::-1] - rgb_mean\n",
    "image = np.expand_dims(image, axis=0)\n",
    "\n",
    "pixel_pos_scores, link_pos_scores = model.predict(image)\n",
    "pixel_pos_scores = softmax(pixel_pos_scores, axis=-1)\n",
    "link_pos_scores_reshaped = link_pos_scores.reshape(link_pos_scores.shape[:-1]+(8, 2))\n",
    "link_pos_scores = softmax(link_pos_scores_reshaped, axis=-1)\n",
    "\n",
    "#masks = decode_batch(pixel_pos_scores, link_pos_scores, pixel_conf_threshold=0.75, link_conf_threshold=0.9)\n",
    "masks = decode_batch(pixel_pos_scores, link_pos_scores, pixel_conf_threshold=0.9, link_conf_threshold=0.95)\n",
    "\n",
    "bboxes = mask_to_bboxes(masks[0], image_ori.shape, min_area=500, min_height=20)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(bboxes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[308 439 308 352 691 352 691 439]\n",
      "(308, 352)\n"
     ]
    }
   ],
   "source": [
    "image_c = image_ori.copy()\n",
    "#cv2.line(image_c,(308,352),(691,439),(0,0,255),2)\n",
    "\n",
    "num_run = 0\n",
    "BREAK_POINT = 1\n",
    "for box in bboxes:\n",
    "    \n",
    "    num_run += 1\n",
    "    \n",
    "    # 裁切區域的 x 與 y 座標（左上角）\n",
    "    x = box[2]\n",
    "    y = box[5]\n",
    "    \n",
    "    # 裁切區域的長度與寬度\n",
    "    h = box[1] - box[5]\n",
    "    w = box[6] - box[2]\n",
    "    \n",
    "\n",
    "    # 裁切圖片\n",
    "    crop_img = image_c[y:y+h, x:x+w]\n",
    "\n",
    "    if num_run == BREAK_POINT:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(308, 352)\n",
      "(691, 439)\n",
      "(303, 520)\n",
      "(699, 440)\n",
      "(392, 520)\n",
      "(479, 595)\n"
     ]
    }
   ],
   "source": [
    "image_c = image_ori.copy()\n",
    "#cv2.line(image_c,(308,352),(691,439),(0,0,255),2)\n",
    "\n",
    "num_run = 0\n",
    "BREAK_POINT = 3\n",
    "for box in bboxes:\n",
    "    points = np.reshape(box, [4, 2])\n",
    "    \n",
    "    pts1 = tuple(points[1])\n",
    "    print(pts1)\n",
    "    \n",
    "    pts3 = tuple(points[3])\n",
    "    print(pts3)\n",
    "    \n",
    "    #break\n",
    "    #cv2.line(image_c,tuple(points[2]),tuple(points[3]),(0,0,255),2)\n",
    "    cv2.circle(image_c, pts1, 5, (25,255,255))  #26\n",
    "    cv2.circle(image_c, pts3, 5, (25,255,25))\n",
    "    \n",
    "    \n",
    "    \n",
    "    #cv2.line(image_c,tuple(points[0]),tuple(points[1]),(0,0,255),2)\n",
    "    #cv2.line(image_c,tuple(points[0]),tuple(points[3]),(0,0,255),2)\n",
    "    #cv2.line(image_c,tuple(points[1]),tuple(points[2]),(0,0,255),2)\n",
    "    #cv2.line(image_c,tuple(points[2]),tuple(points[3]),(0,0,255),2)\n",
    "    \n",
    "    if num_run == BREAK_POINT:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[308 439]\n",
      " [308 352]\n",
      " [691 352]\n",
      " [691 439]]\n",
      "[[698 525]\n",
      " [303 520]\n",
      " [304 435]\n",
      " [699 440]]\n",
      "[[392 595]\n",
      " [392 520]\n",
      " [479 520]\n",
      " [479 595]]\n"
     ]
    }
   ],
   "source": [
    "image_c = image_ori.copy()\n",
    "#cv2.line(image_c,(308,352),(691,439),(0,0,255),2)\n",
    "\n",
    "num_run = 0\n",
    "BREAK_POINT = 3\n",
    "for box in bboxes:\n",
    "    points = np.reshape(box, [4, 2])\n",
    "    print(points)\n",
    "\n",
    "    \n",
    "    #break\n",
    "    #cv2.line(image_c,tuple(points[2]),tuple(points[3]),(0,0,255),2)\n",
    "    \n",
    "    cv2.line(image_c,tuple(points[0]),tuple(points[1]),(0,0,255),2)\n",
    "    cv2.line(image_c,tuple(points[0]),tuple(points[3]),(0,0,255),2)\n",
    "    cv2.line(image_c,tuple(points[1]),tuple(points[2]),(0,0,255),2)\n",
    "    cv2.line(image_c,tuple(points[2]),tuple(points[3]),(0,0,255),2)\n",
    "    \n",
    "    if num_run == BREAK_POINT:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv2.imshow('image', image_c)\n",
    "cv2.imshow('crop_img', crop_img)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "#cv2.imwrite('TOP_29_121222_res.jpg', image_c)\n",
    "#cv2.imwrite('TOP_29_121222_res_crop_img03.jpg', crop_img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
