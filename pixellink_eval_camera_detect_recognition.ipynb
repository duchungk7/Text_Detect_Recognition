{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#-*- coding:utf-8 -*-\n",
    "#'''\n",
    "# Created on 18-10-15\n",
    "#\n",
    "# @Author: Greg Gao(laygin)\n",
    "#'''\n",
    "import os\n",
    "import numpy as np\n",
    "import cv2\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = ''\n",
    "import imutils\n",
    "from pixellink_model import create_pixellink_model\n",
    "from pixellink_utils import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\duchu\\Anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n"
     ]
    }
   ],
   "source": [
    "r_mean = 123.\n",
    "g_mean = 117.\n",
    "b_mean = 104.\n",
    "rgb_mean = [r_mean, g_mean, b_mean]\n",
    "\n",
    "\n",
    "#img_path = './samples/TOP_29_121222.jpg'\n",
    "save_weights = './weights/pixellink.h5'\n",
    "model = create_pixellink_model(acf='relu')\n",
    "model.load_weights(save_weights)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "capture device is open: True\n"
     ]
    }
   ],
   "source": [
    "# 設定 影片 解析度\n",
    "video_width = 640\n",
    "video_height = 480\n",
    "\n",
    "#cap = cv2.VideoCapture(0)   # device number 0\n",
    "cap = cv2.VideoCapture(0)   # device number 1\n",
    "cap.set(cv2.CAP_PROP_FRAME_WIDTH, video_width)\n",
    "cap.set(cv2.CAP_PROP_FRAME_HEIGHT, video_height)\n",
    "print(\"capture device is open: \" + str(cap.isOpened()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# While-loop 主程式"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop to read image  \n",
    "while True:\n",
    "\n",
    "    # keyboard input value\n",
    "    key = cv2.waitKey(1) & 0xFF\n",
    "\n",
    "    # read from camera\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    if ret:  # success read\n",
    "        image, *r = resize_image(frame)\n",
    "        image_ori = image.copy()\n",
    "        image = image[...,::-1] - rgb_mean\n",
    "        image = np.expand_dims(image, axis=0)\n",
    "\n",
    "        pixel_pos_scores, link_pos_scores = model.predict(image)\n",
    "        pixel_pos_scores = softmax(pixel_pos_scores, axis=-1)\n",
    "        link_pos_scores_reshaped = link_pos_scores.reshape(link_pos_scores.shape[:-1]+(8, 2))\n",
    "        link_pos_scores = softmax(link_pos_scores_reshaped, axis=-1)\n",
    "\n",
    "        #masks = decode_batch(pixel_pos_scores, link_pos_scores, pixel_conf_threshold=0.75, link_conf_threshold=0.9)\n",
    "        masks = decode_batch(pixel_pos_scores, link_pos_scores, pixel_conf_threshold=0.75, link_conf_threshold=0.98)\n",
    "\n",
    "        bboxes = mask_to_bboxes(masks[0], image_ori.shape, min_area=300, min_height=30)\n",
    "        \n",
    "        \n",
    "        image_c = image_ori.copy()\n",
    "        for box in bboxes:\n",
    "            points = np.reshape(box, [4, 2])\n",
    "            cv2.line(image_c,tuple(points[0]),tuple(points[1]),(0,0,255),2)\n",
    "            cv2.line(image_c,tuple(points[0]),tuple(points[3]),(0,0,255),2)\n",
    "            cv2.line(image_c,tuple(points[1]),tuple(points[2]),(0,0,255),2)\n",
    "            cv2.line(image_c,tuple(points[2]),tuple(points[3]),(0,0,255),2)\n",
    "        \n",
    "        #if start_video:     # start\n",
    "        #    out.write(frame)\n",
    "        #    frame_count += 1\n",
    "\n",
    "    \n",
    "        #cv2.putText(frame, str(frame_count) , (40, 50), cv2.FONT_HERSHEY_COMPLEX_SMALL,1, (255, 0, 255), 1, cv2.LINE_AA)\n",
    "        cv2.imshow('frame', frame)\n",
    "        cv2.imshow('detect result', image_c)\n",
    "        \n",
    "    else:\n",
    "        print('camera read fail.')\n",
    "        break\n",
    "\n",
    "    #if frame_count > FRAME_NUM:   # FPS: 30, so 30秒產生 900張\n",
    "    #    break\n",
    "    if key == ord('q'):     # press 'q' to leave while\n",
    "        break\n",
    "    #if key == ord(' '):     # press 's' to start\n",
    "    #    print('Starting capture video...')\n",
    "    #    start_video = True\n",
    "\n",
    "# release VideoWriter object clsoe all windows\n",
    "#out.release()\n",
    "cap.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
